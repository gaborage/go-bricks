# Example configuration file demonstrating both standard and custom configurations

# Standard framework configurations
app:
  name: my-service
  version: v1.0.0
  env: development
  debug: true
  namespace: default
  rate:
    limit: 100
    burst: 200
    ippreguard:
      enabled: false
      threshold: 2000          # IP rate limit threshold (requests per second)

server:
  host: 0.0.0.0
  port: 8080
  timeout:
    read: 15s
    write: 30s
    idle: 60s
    middleware: 5s
    shutdown: 10s
  path:
    base: ""          # Global prefix for all routes (e.g., "/api/v1")
    health: /health   # Custom health endpoint path
    ready: /ready     # Custom readiness endpoint path

database:
  type: postgresql
  host: localhost
  port: 5432
  database: myapp_db
  username: myapp_user
  password: myapp_password

  connectionstring: ""  # Optional: override with full connection string

  pool:
    max:
      connections: 25
    idle:
      connections: 5
      time: 4m                     # Recycle idle connections before NAT/LB timeout (AWS: 350s)
    lifetime:
      max: 30m
    keepalive:
      enabled: true                # Enable TCP keep-alive probes (recommended for cloud deployments)
      interval: 60s                # Send probe every 60s to prevent NAT/LB from dropping connection

  query:
    slow:
      threshold: 100ms
      enabled: true
    log:
      parameters: true
      max: 1000

  tls:
    mode: disable
    cert: ""
    key: ""
    ca: ""

  # Oracle-specific configuration
  oracle:
    service:
      name: ORCL
      sid: ""

# Cache configuration (OPTIONAL - Redis-based caching)
# If not using cache, set enabled: false or omit this section
cache:
  enabled: false                    # Enable/disable cache functionality
  type: redis                        # Cache backend type (currently only "redis" supported)
  redis:
    host: localhost                  # Redis server hostname
    port: 6379                       # Redis server port
    password: ""                     # Redis password (use environment variable: CACHE_REDIS_PASSWORD)
    database: 0                      # Redis database number (0-15)
    poolsize: 10                     # Maximum number of connections in pool
    dialtimeout: 5s                  # Timeout for establishing new connections
    readtimeout: 3s                  # Timeout for read operations (-1 = no timeout)
    writetimeout: 3s                 # Timeout for write operations (-1 = no timeout)
    maxretries: 3                    # Maximum number of retries before giving up
    minretrybackoff: 8ms             # Minimum backoff between retries
    maxretrybackoff: 512ms           # Maximum backoff between retries

log:
  level: debug
  pretty: true
  output:
    format: json
    file: ""

# Messaging configuration (OPTIONAL - only required if using AMQP/RabbitMQ)
# If not using messaging, you can omit this entire section or leave broker.url empty
messaging:
  broker:
    url: amqp://localhost:5672/
    virtualhost: /
  routing:
    exchange: my-exchange
    key: my-routing-key
  headers:
    x-app-name: my-service
    x-environment: development

multitenant:
  enabled: false
  resolver:
    type: header                 # Options: header, subdomain, composite
    header: X-Tenant-ID          # Header name for header-based resolution
    domain: api.example.com      # Root domain (leading dot optional)
    proxies: false               # Trust X-Forwarded-Host header
  cache:
    ttl: 5m                      # Time-to-live for cached tenant configurations
  limits:
    tenants: 100                 # Maximum number of active tenant connections
    cleanup:
      interval: 5m               # Idle connection cleanup cadence
  validation:
    pattern: "^[a-z0-9-]{1,64}$" # Regex pattern for validating tenant IDs

# Phase 2 (example provider data):
# tenants:
#   tenant-a:
#     database:
#       host: tenant-a.db.example.com
#       port: 5432
#       database: tenant_a_prod
#       username: app_user
#       password: secure_password
#     messaging:
#       url: amqp://rabbitmq.example.com:5672/tenant-a  # Optional - omit if tenant doesn't use messaging

# Custom configurations - add your application-specific settings here
custom:
  # Feature flags
  flags:
    home:
      v2: 
        enabled: true

  # Service-specific configurations
  service:
    api:
      endpoint: https://api.example.com/v1
      # DO NOT commit real secrets to config files; prefer env vars or secret stores.
      key: your-api-key-here
    timeout: 30s
    retries: 
      max: 3
      delay: 5s
    batch: 
      size: 100

  # Cache settings
  cache:
    redis:
      url: localhost:6379
      ttl: 5m
      entries:
        max: 10000

  # Notification settings
  notifications:
    email:
      enabled: true
      smtp:
        host: smtp.example.com
        port: 587
        from: noreply@example.com

    slack:
      enabled: false
      webhook:
        url: https://hooks.slack.com/services/YOUR/WEBHOOK/URL
      channel: "#alerts"

  # Security settings
  security:
    jwt:
      secret: your-secret-key-here
      expiry: 24h
    password:
      length:
        min: 8
        max: 64
    2fa:
      required: false
    origins:
      allowed:
      - http://localhost:3000
      - https://app.example.com

observability:
  # enabled controls whether observability features are active.
  # When false, all observability operations become no-ops with zero overhead.
  # Default: false
  enabled: true

  # service section defines service identification metadata
  service:
    # name is required when observability is enabled.
    # This identifies your service in traces and metrics.
    # Can be overridden by environment variable: OBSERVABILITY_SERVICE_NAME
    name: "my-service"

    # version specifies the version of your service.
    # Used for filtering and grouping in observability backends.
    # Can be overridden by environment variable: OBSERVABILITY_SERVICE_VERSION
    # Default: "unknown"
    version: "1.0.0"

  # environment indicates the deployment environment.
  # Common values: development, staging, production
  # Can be overridden by environment variable: OBSERVABILITY_ENVIRONMENT
  # Default: "development"
  environment: "production"

  # trace section configures distributed tracing
  trace:
    # enabled controls whether tracing is active.
    # Can be disabled independently of metrics.
    # Can be overridden by environment variable: OBSERVABILITY_TRACE_ENABLED
    # Default: true
    enabled: true

    # endpoint specifies where to send trace data.
    # Special value "stdout" enables console logging for local development.
    # For production, use OTLP gRPC endpoint: "http://localhost:4318" or "grpc://localhost:4317"
    # For DataDog, point to the DataDog Agent's OTLP endpoint.
    # Can be overridden by environment variable: OBSERVABILITY_TRACE_ENDPOINT
    # Default: "stdout"
    endpoint: "stdout"

    # sample.rate controls what fraction of traces to collect (0.0 to 1.0).
    # 1.0 = collect all traces (use in development/staging)
    # 0.1 = collect 10% of traces (reduces costs in production)
    # 0.01 = collect 1% of traces (high-volume production)
    # Can be overridden by environment variable: OBSERVABILITY_TRACE_SAMPLE_RATE
    # Default: 1.0
    sample:
      rate: 1.0

    # batch.timeout specifies how long to wait before sending a batch of spans.
    # Lower values reduce latency but increase network overhead.
    # Can be overridden by environment variable: OBSERVABILITY_TRACE_BATCH_TIMEOUT
    # Default: 5s
    batch:
      timeout: 5s

    # export.timeout specifies the maximum time to wait for span export.
    # Prevents slow backends from blocking the application.
    # Can be overridden by environment variable: OBSERVABILITY_TRACE_EXPORT_TIMEOUT
    # Default: 30s
    export:
      timeout: 30s

    # max.queue.size limits the number of spans buffered for export.
    # Prevents memory exhaustion under high load.
    # Can be overridden by environment variable: OBSERVABILITY_TRACE_MAX_QUEUE_SIZE
    # Default: 2048
    max:
      queue:
        size: 2048
      batch:
        # max.batch.size limits the number of spans per export batch.
        # Smaller batches reduce latency, larger batches reduce overhead.
        # Can be overridden by environment variable: OBSERVABILITY_TRACE_MAX_BATCH_SIZE
        # Default: 512
        size: 512

  # metrics section configures metrics collection
  metrics:
    # enabled controls whether metrics collection is active.
    # Can be disabled independently of tracing.
    # Can be overridden by environment variable: OBSERVABILITY_METRICS_ENABLED
    # Default: true
    enabled: true

    # endpoint specifies where to send metric data.
    # Special value "stdout" enables console logging for local development.
    # For production, use OTLP endpoint (http or grpc, depending on collector).
    # Can be overridden by environment variable: OBSERVABILITY_METRICS_ENDPOINT
    # Default: "stdout"
    endpoint: "stdout"

    # protocol specifies the OTLP protocol to use ("http" or "grpc").
    # When unset, metrics inherit the trace protocol (default "http").
    # Can be overridden by OBSERVABILITY_METRICS_PROTOCOL.
    protocol: ""

    # insecure controls whether to use insecure connections (no TLS).
    # Omit or set to null to inherit the trace setting (default true).
    # insecure: false

    # headers allows custom headers for metric exporters (e.g., API keys).
    # When omitted, metrics inherit trace headers.
    headers: {}

    # interval specifies how often to export metrics.
    # Shorter intervals provide more real-time data but increase overhead.
    # Can be overridden by environment variable: OBSERVABILITY_METRICS_INTERVAL
    # Default: 10s
    interval: 10s

    # export.timeout specifies the maximum time to wait for metric export.
    # Can be overridden by environment variable: OBSERVABILITY_METRICS_EXPORT_TIMEOUT
    # Default: 30s
    export:
      timeout: 30s

# ─────────────────────────────────────────────────────────────────────────────
# Environment-Specific Examples
# ─────────────────────────────────────────────────────────────────────────────

# Local Development (console output):
# observability:
#   enabled: true
#   service:
#     name: "my-service"
#   trace:
#     endpoint: "stdout"
#   metrics:
#     endpoint: "stdout"

# Production with DataDog:
# observability:
#   enabled: true
#   service:
#     name: "my-service"
#     version: "1.2.3"
#   environment: "production"
#   trace:
#     endpoint: "grpc://localhost:4317"  # DataDog Agent OTLP receiver (gRPC)
#     protocol: "grpc"
#     insecure: true
#     sample:
#       rate: 0.1  # 10% sampling for cost control
#   metrics:
#     endpoint: "https://api.datadoghq.com"
#     protocol: "http"
#     insecure: false
#     headers:
#       DD-API-KEY: "${DATADOG_API_KEY}"
#     interval: 30s

# High-Volume Production (aggressive sampling):
# observability:
#   enabled: true
#   service:
#     name: "my-service"
#   trace:
#     endpoint: "http://localhost:4318"
#     sample:
#       rate: 0.01  # 1% sampling
#     max:
#       queue:
#         size: 4096  # Larger buffer for bursts
#   metrics:
#     interval: 60s  # Less frequent metric exports
